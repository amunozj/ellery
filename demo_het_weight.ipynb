{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7383ace3-8c73-4863-aae4-dc507e9aa674",
   "metadata": {},
   "source": [
    "# Self-consistent, Bayesian SSN calibration and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aed6bb-1d85-42db-8413-c55fdbcadd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS\n",
    "from numpyro import distributions as dist\n",
    "\n",
    "# Set the number of cores on your machine for parallelism:\n",
    "cpu_cores = 4\n",
    "numpyro.set_host_device_count(cpu_cores)\n",
    "\n",
    "from jax import (\n",
    "    numpy as jnp, vmap, config, lax, \n",
    "    tree_map, tree_flatten, tree_leaves\n",
    ")\n",
    "from jax.random import PRNGKey, split\n",
    "from jax.flatten_util import ravel_pytree\n",
    "\n",
    "config.update('jax_enable_x64', True)\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import arviz\n",
    "from corner import corner\n",
    "\n",
    "from celerite2.jax import terms, GaussianProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e2bf1-757d-44a7-bf44-41076273089e",
   "metadata": {},
   "source": [
    "### Generate synthetic observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42470ef4-52de-4ede-8ae8-b3ede4196931",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "t_start = 1600\n",
    "t_stop = 2022\n",
    "t = np.linspace(t_start, t_stop, 1000)\n",
    "\n",
    "# Specify the frequency of observations, which increases sharply after 1800:\n",
    "data_collection_rate = 1 / (np.exp((1800 - t) / 10) + 1) + 0.5\n",
    "data_collection_rate_cdf = np.cumsum(data_collection_rate)\n",
    "data_collection_rate_cdf /= data_collection_rate_cdf.max()\n",
    "\n",
    "amp_mod = gaussian_filter1d(\n",
    "    np.random.uniform(size=len(t)), 100\n",
    ")\n",
    "\n",
    "y = (\n",
    "    20 * (amp_mod - amp_mod.min() + 0)/amp_mod.ptp() * \n",
    "    np.cos(2 * np.pi * t / 2 / 11)**2\n",
    ")\n",
    "\n",
    "observers = []\n",
    "\n",
    "N_observers = 100\n",
    "\n",
    "# true_weight = np.concatenate([[1], np.random.uniform(0.2, 1, size=N_observers-1)])\n",
    "true_weight = np.concatenate([[1], 1-np.abs(np.random.normal(0, 0.3, size=N_observers-1))])\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i in range(N_observers):\n",
    "    # Randomly choose start/stop times for observer\n",
    "\n",
    "    if i == 0:\n",
    "        tbounds = [1930, 1990]\n",
    "    else:\n",
    "        tbounds = np.interp(\n",
    "            np.random.uniform(0, 1, size=2), \n",
    "            data_collection_rate_cdf, \n",
    "            t\n",
    "        )\n",
    "\n",
    "    # Randomly distribute observations within start/stop time\n",
    "    \n",
    "    N_observations_per_observer = (\n",
    "        max(int(np.random.lognormal(np.log(30), 0.5)), 50) \n",
    "        if i > 0 else 600\n",
    "    )\n",
    "    x_obs = np.sort(np.random.uniform(\n",
    "        tbounds[0], \n",
    "        tbounds[1], \n",
    "        N_observations_per_observer\n",
    "    ))\n",
    "    noise_scale = 0.2\n",
    "    noise = np.random.normal(scale=noise_scale, size=len(x_obs))\n",
    "    y_obs = np.interp(x_obs, t, y) * true_weight[i] + noise\n",
    "    y_err = jnp.broadcast_to(1, x_obs.shape) \n",
    "    #* 10 / N_observations_per_observer**0.5 # np.max([\n",
    "    #     4 * (t_stop - x_obs) / (t_stop - t_start), \n",
    "    #     jnp.broadcast_to(noise_scale, x_obs.shape)\n",
    "    # ], axis=0)\n",
    "    \n",
    "    observers.append([x_obs, y_obs, y_err])\n",
    "\n",
    "    plt.errorbar(\n",
    "        x_obs, y_obs / true_weight[i], y_err, \n",
    "        fmt='.', color='k', ecolor='silver'\n",
    "    )\n",
    "plt.plot(t, y, zorder=10)\n",
    "plt.gca().set(ylabel='SSN');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a17732-1536-46db-81b7-329ce93fdf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stack = [jnp.array(x) for x, y, yerr in observers]\n",
    "y_stack = [jnp.array(y) for x, y, yerr in observers]\n",
    "y_stack_errs = [jnp.array(yerr) for x, y, yerr in observers]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec937db5-ff8b-4a72-b805-a890978af414",
   "metadata": {},
   "source": [
    "This \"first\" time series is taken as the ground-truth against which all others are calibrated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d7744-d143-4dde-b189-8403ffde7de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = [yi.shape[0] for yi in y_stack]\n",
    "mask = [yi.shape[0] == max(npoints) for yi in y_stack]\n",
    "plt.errorbar(x_stack[i], y_stack[i], y_stack_errs[i], fmt='.', ecolor='silver')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494cee35-b2ca-48d9-a144-d10f8aea8b1f",
   "metadata": {},
   "source": [
    "### Define a model with jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c25d48-bf55-421e-98e2-7888dc19caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = jnp.argsort(ravel_pytree(x_stack)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9134242-8a33-4a9d-ad0c-41efb8ef0a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 100.0 \n",
    "\n",
    "def numpyro_model(x_stack, y_stack, y_stack_errs):    \n",
    "    weight = numpyro.sample(\n",
    "        'weight', dist.TwoSidedTruncatedDistribution(\n",
    "            dist.Normal(loc=1, scale=0.1), low=0, high=1),\n",
    "        sample_shape=(N_observers - 1,),\n",
    "    )\n",
    "    # weight = numpyro.sample(\n",
    "    #     'weight', dist.Uniform(low=0, high=1),\n",
    "    #     sample_shape=(N_observers - 1,),\n",
    "    # )\n",
    "    # weight = numpyro.sample(\n",
    "    #     'weight', dist.TwoSidedTruncatedDistribution(\n",
    "    #         dist.Normal(\n",
    "    #             loc=jnp.array(true_weight),\n",
    "    #             scale=0.1 * jnp.ones_like(true_weight)\n",
    "    #     ), low=0, high=1\n",
    "    #     )#sample_shape=(N_observers,),\n",
    "    # )\n",
    "\n",
    "    y_tree = tree_map(lambda yi, w: yi / w, y_stack, [1] + list(weight))\n",
    "    y_weighted_sorted = ravel_pytree(y_tree)[0][sort]\n",
    "\n",
    "    # the GP is parameterized by an amplitude S0\n",
    "    S0 = numpyro.sample('S0', dist.HalfNormal(scale=20))\n",
    "    mu = numpyro.sample('mu', dist.Uniform(low=-20, high=20))\n",
    "    # We fix the SHO period to the solar cycle period \n",
    "    kernel = terms.UnderdampedSHOTerm(\n",
    "        S0=S0, w0=2*np.pi/11, Q=Q\n",
    "    )\n",
    "    diag_scale = numpyro.sample('diag_scale', dist.Uniform(low=0.01, high=100))\n",
    "    # construct a GP\n",
    "    gp = GaussianProcess(\n",
    "        kernel, \n",
    "        t=ravel_pytree(x_stack)[0][sort], \n",
    "        diag=diag_scale * ravel_pytree(y_stack_errs)[0][sort]**2,\n",
    "        mean=mu, \n",
    "        check_sorted=False\n",
    "    )   \n",
    "    numpyro.sample(\n",
    "        'obs', gp.numpyro_dist(), obs=y_weighted_sorted\n",
    "    )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a9199-0c12-44ac-a8e0-8698b8f3c538",
   "metadata": {},
   "source": [
    "### Run posterior sampling with numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff936983-132b-470d-8e08-dc82a1108b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_seed = 42\n",
    "rng_keys = split(\n",
    "    PRNGKey(rng_seed), \n",
    "    cpu_cores\n",
    ")\n",
    "\n",
    "sampler = NUTS(\n",
    "    numpyro_model, \n",
    "    dense_mass=True\n",
    ")\n",
    "\n",
    "# Monte Carlo sampling for a number of steps and parallel chains: \n",
    "mcmc = MCMC(\n",
    "    sampler, \n",
    "    num_warmup=100, \n",
    "    num_samples=500, \n",
    "    num_chains=4\n",
    ")\n",
    "\n",
    "# Run the MCMC\n",
    "mcmc.run(rng_keys, x_stack, y_stack, y_stack_errs)\n",
    "\n",
    "result = arviz.from_numpyro(mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6c6f93-409f-42fd-8152-489b85b9f6d1",
   "metadata": {},
   "source": [
    "### Plot posteriors for the bias of each observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90cdad-ee30-48a5-b3be-5e001cbd6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot every `skip`th weight posterior\n",
    "skip = 10\n",
    "corner(\n",
    "    result.posterior.weight.to_numpy().reshape(\n",
    "        (-1, N_observers - 1)\n",
    "    )[:, ::skip],\n",
    "    truths=true_weight[1:][::skip],\n",
    "    quiet=True, plot_datapoints=False\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539f3dc-6e33-4b5d-b966-44361850d7c1",
   "metadata": {},
   "source": [
    "### Plot the posteriors for the GP hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12abd1-7960-4283-8f8b-5bcf11b35bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corner(\n",
    "    result, var_names=['S0', 'mu', 'diag_scale'],\n",
    "    quiet=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d2f4d-3c39-48d4-8287-b7ded822df96",
   "metadata": {},
   "source": [
    "### Plot the maximum-likelihood model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99261279-1e90-4dbc-bbdb-463de819e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = terms.UnderdampedSHOTerm(\n",
    "    S0=result.posterior.S0.to_numpy().flatten().mean(), \n",
    "    w0=2*np.pi/11, \n",
    "    Q=Q\n",
    ")\n",
    "\n",
    "weight_means = np.concatenate([[1], result.posterior.weight.to_numpy().reshape(\n",
    "    (-1, N_observers - 1)\n",
    ").mean(0)])\n",
    "model = ravel_pytree(\n",
    "    tree_map(lambda yi, w: yi / w, y_stack, list(weight_means))\n",
    ")[0][sort]\n",
    "\n",
    "# construct a GP\n",
    "gp = GaussianProcess(\n",
    "    kernel,\n",
    "    t=ravel_pytree(x_stack)[0][sort], \n",
    "    diag=ravel_pytree(y_stack_errs)[0][sort]**2,\n",
    "    check_sorted=False, \n",
    "    mean=result.posterior.mu.to_numpy().flatten().mean()\n",
    ")\n",
    "\n",
    "# We'll predict on a new timeseries that goes beyond the input bounds\n",
    "t_pred = np.linspace(t_start - 10, t_stop + 10, 1000)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "y_pred, y_pred_var = gp.predict(\n",
    "    model, t=t_pred, \n",
    "    return_var=True\n",
    ")\n",
    "\n",
    "plt.plot(t_pred, y_pred, label='GP-inferred SSN')\n",
    "plt.fill_between(\n",
    "    t_pred, \n",
    "    y_pred - np.sqrt(y_pred_var), \n",
    "    y_pred + np.sqrt(y_pred_var), \n",
    "    alpha=0.2, zorder=10\n",
    ")\n",
    "for i in range(len(x_stack)):\n",
    "    plt.plot(\n",
    "        x_stack[i], y_stack[i] / weight_means[i], \n",
    "        '.', zorder=-10, alpha=1,\n",
    "    )\n",
    "\n",
    "plt.plot(t, y, label='Input SSN')\n",
    "plt.legend()\n",
    "plt.gca().set(ylabel='SSN', ylim=[-5, 1.1*y.max()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908579b2-3681-44c7-98b0-6afdc7c24fc5",
   "metadata": {},
   "source": [
    "### Compare inference with truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa848f-4612-45d7-a559-affa2c626ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferred_weight.mean(0).shape, true_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294e152-077e-4130-9067-8eeff9d6dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_weight = result.posterior.weight.to_numpy().reshape((-1, N_observers - 1))\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.scatter(true_weight[1:], inferred_weight.mean(0), marker='.', c=npoints[1:])\n",
    "plt.errorbar(\n",
    "    true_weight[1:], inferred_weight.mean(0), inferred_weight.std(0), \n",
    "    fmt=',', zorder=-2, ecolor='silver'\n",
    ")\n",
    "plt.colorbar()\n",
    "mm = [inferred_weight.mean(0).min(), inferred_weight.mean(0).max()]\n",
    "plt.plot(mm, mm, ls='--', color='silver')\n",
    "plt.gca().set(\n",
    "    xlabel='True weight', ylabel='Inferred weight'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c98c2a-4c8c-4367-b82a-55171fc1a63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d412e-4b61-40f3-98b4-0476de14a0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
